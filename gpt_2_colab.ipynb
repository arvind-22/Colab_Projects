{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gpt-2_colab.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arvind-22/Colab_Projects/blob/main/gpt_2_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bf4ETsCYGAVi"
      },
      "source": [
        "## Mount Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0jzA5ccF5tC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8af8dcb3-9324-41dc-bbd1-4c13bd41ef60"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DbmfFQLnGESb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "94949aa4-0df4-4955-c80b-d1f5ac868bbf"
      },
      "source": [
        "# ONLY RUN ONCE\n",
        "# Create gpt-2 folder \n",
        "%cd /content/drive/My\\ Drive/\n",
        "!mkdir gpt-2\n",
        "%cd gpt-2/\n",
        "!git clone https://github.com/openai/gpt-2.git\n",
        "%cd cd gpt-2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive\n",
            "/content/drive/My Drive/gpt-2\n",
            "Cloning into 'gpt-2'...\n",
            "remote: Enumerating objects: 230, done.\u001b[K\n",
            "remote: Total 230 (delta 0), reused 0 (delta 0), pack-reused 230\u001b[K\n",
            "Receiving objects: 100% (230/230), 4.38 MiB | 3.33 MiB/s, done.\n",
            "Resolving deltas: 100% (118/118), done.\n",
            "[Errno 2] No such file or directory: 'cd gpt-2'\n",
            "/content/drive/My Drive/gpt-2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EvbghngXHaZV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3048b12d-2455-4260-ebfd-04cd7db1b774"
      },
      "source": [
        "%cd /content/drive/My\\ Drive/gpt-2/gpt-2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/gpt-2/gpt-2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HniGguitGweL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4bdb07f0-411d-470a-f7f6-bd4f92ac4d70"
      },
      "source": [
        "# Change tensorflow version\n",
        "%tensorflow_version 1.x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-evMyA-G5-H",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 905
        },
        "outputId": "03ded7aa-59be-49c8-ceb6-e3da3809c386"
      },
      "source": [
        "# Install requirement.txt\n",
        "!pip3 install -r requirements.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting fire>=0.1.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/34/a7/0e22e70778aca01a52b9c899d9c145c6396d7b613719cd63db97ffa13f2f/fire-0.3.1.tar.gz (81kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 1.6MB/s \n",
            "\u001b[?25hCollecting regex==2017.4.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/36/62/c0c0d762ffd4ffaf39f372eb8561b8d491a11ace5a7884610424a8b40f95/regex-2017.04.05.tar.gz (601kB)\n",
            "\u001b[K     |████████████████████████████████| 604kB 5.6MB/s \n",
            "\u001b[?25hCollecting requests==2.21.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/e3/20f3d364d6c8e5d2353c72a67778eb189176f08e873c9900e10c0287b84b/requests-2.21.0-py2.py3-none-any.whl (57kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 6.1MB/s \n",
            "\u001b[?25hCollecting tqdm==4.31.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6c/4b/c38b5144cf167c4f52288517436ccafefe9dc01b8d1c190e18a6b154cd4a/tqdm-4.31.1-py2.py3-none-any.whl (48kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from fire>=0.1.3->-r requirements.txt (line 1)) (1.15.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.6/dist-packages (from fire>=0.1.3->-r requirements.txt (line 1)) (1.1.0)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests==2.21.0->-r requirements.txt (line 3)) (3.0.4)\n",
            "Collecting idna<2.9,>=2.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/2c/cd551d81dbe15200be1cf41cd03869a46fe7226e7450af7a6545bfc474c9/idna-2.8-py2.py3-none-any.whl (58kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 6.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests==2.21.0->-r requirements.txt (line 3)) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests==2.21.0->-r requirements.txt (line 3)) (2020.6.20)\n",
            "Building wheels for collected packages: fire, regex\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.3.1-py2.py3-none-any.whl size=111005 sha256=d9a76e6a8697419e5974a2c860a65ef38e110209dee45861214c7f706f93228e\n",
            "  Stored in directory: /root/.cache/pip/wheels/c1/61/df/768b03527bf006b546dce284eb4249b185669e65afc5fbb2ac\n",
            "  Building wheel for regex (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for regex: filename=regex-2017.4.5-cp36-cp36m-linux_x86_64.whl size=533215 sha256=e1b2fbecfb2afe17016f267968485a8f801a71183215c9026315ff14d24a7054\n",
            "  Stored in directory: /root/.cache/pip/wheels/75/07/38/3c16b529d50cb4e0cd3dbc7b75cece8a09c132692c74450b01\n",
            "Successfully built fire regex\n",
            "\u001b[31mERROR: spacy 2.2.4 has requirement tqdm<5.0.0,>=4.38.0, but you'll have tqdm 4.31.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement requests~=2.23.0, but you'll have requests 2.21.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: fbprophet 0.7.1 has requirement tqdm>=4.36.1, but you'll have tqdm 4.31.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: fire, regex, idna, requests, tqdm\n",
            "  Found existing installation: regex 2019.12.20\n",
            "    Uninstalling regex-2019.12.20:\n",
            "      Successfully uninstalled regex-2019.12.20\n",
            "  Found existing installation: idna 2.10\n",
            "    Uninstalling idna-2.10:\n",
            "      Successfully uninstalled idna-2.10\n",
            "  Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Found existing installation: tqdm 4.41.1\n",
            "    Uninstalling tqdm-4.41.1:\n",
            "      Successfully uninstalled tqdm-4.41.1\n",
            "Successfully installed fire-0.3.1 idna-2.8 regex-2017.4.5 requests-2.21.0 tqdm-4.31.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "idna",
                  "requests"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JIbLyEBmHCrM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "outputId": "540ee501-8cc6-48be-c958-a05cd550e47e"
      },
      "source": [
        "!python3 download_model.py 124M\n",
        "!python3 download_model.py 355M\n",
        "!python3 download_model.py 774M\n",
        "!python3 download_model.py 1558M"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fetching checkpoint: 1.00kit [00:00, 833kit/s]                                                      \n",
            "Fetching encoder.json: 1.04Mit [00:00, 43.3Mit/s]                                                   \n",
            "Fetching hparams.json: 1.00kit [00:00, 765kit/s]                                                    \n",
            "Fetching model.ckpt.data-00000-of-00001: 498Mit [00:07, 62.6Mit/s]                                  \n",
            "Fetching model.ckpt.index: 6.00kit [00:00, 3.12Mit/s]                                               \n",
            "Fetching model.ckpt.meta: 472kit [00:00, 17.4Mit/s]                                                 \n",
            "Fetching vocab.bpe: 457kit [00:00, 37.4Mit/s]                                                       \n",
            "Fetching checkpoint: 1.00kit [00:00, 587kit/s]                                                      \n",
            "Fetching encoder.json: 1.04Mit [00:00, 23.1Mit/s]                                                   \n",
            "Fetching hparams.json: 1.00kit [00:00, 567kit/s]                                                    \n",
            "Fetching model.ckpt.data-00000-of-00001: 1.42Git [00:24, 58.3Mit/s]                                 \n",
            "Fetching model.ckpt.index: 11.0kit [00:00, 6.81Mit/s]                                               \n",
            "Fetching model.ckpt.meta: 927kit [00:00, 39.2Mit/s]                                                 \n",
            "Fetching vocab.bpe: 457kit [00:00, 53.3Mit/s]                                                       \n",
            "Fetching checkpoint: 1.00kit [00:00, 776kit/s]                                                      \n",
            "Fetching encoder.json: 1.04Mit [00:00, 51.5Mit/s]                                                   \n",
            "Fetching hparams.json: 1.00kit [00:00, 707kit/s]                                                    \n",
            "Fetching model.ckpt.data-00000-of-00001: 3.10Git [00:52, 59.5Mit/s]                                 \n",
            "Fetching model.ckpt.index: 16.0kit [00:00, 9.99Mit/s]                                               \n",
            "Fetching model.ckpt.meta: 1.38Mit [00:00, 51.9Mit/s]                                                \n",
            "Fetching vocab.bpe: 457kit [00:00, 52.4Mit/s]                                                       \n",
            "Fetching checkpoint: 1.00kit [00:00, 673kit/s]                                                      \n",
            "Fetching encoder.json: 1.04Mit [00:00, 51.1Mit/s]                                                   \n",
            "Fetching hparams.json: 1.00kit [00:00, 636kit/s]                                                    \n",
            "Fetching model.ckpt.data-00000-of-00001: 6.23Git [02:32, 40.9Mit/s]                                 \n",
            "Fetching model.ckpt.index: 21.0kit [00:00, 10.9Mit/s]                                               \n",
            "Fetching model.ckpt.meta: 1.84Mit [00:00, 48.8Mit/s]                                                \n",
            "Fetching vocab.bpe: 457kit [00:00, 41.4Mit/s]                                                       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbpy2zDtIKnf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c13a0cc-2307-44c9-a178-bac983cc5b26"
      },
      "source": [
        "!python3 src/interactive_conditional_samples.py --top_k 40"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From src/interactive_conditional_samples.py:57: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "2022-06-25 09:55:01.981213: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2022-06-25 09:55:01.995384: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "2022-06-25 09:55:01.995472: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (a6106a15e87d): /proc/driver/nvidia/version does not exist\n",
            "2022-06-25 09:55:02.004072: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2199995000 Hz\n",
            "2022-06-25 09:55:02.004370: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1b46f40 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2022-06-25 09:55:02.004409: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "WARNING:tensorflow:From src/interactive_conditional_samples.py:58: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From src/interactive_conditional_samples.py:60: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/MyDrive/gpt-2/gpt-2/src/sample.py:51: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/MyDrive/gpt-2/gpt-2/src/model.py:148: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/MyDrive/gpt-2/gpt-2/src/model.py:152: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/MyDrive/gpt-2/gpt-2/src/model.py:36: The name tf.rsqrt is deprecated. Please use tf.math.rsqrt instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/drive/MyDrive/gpt-2/gpt-2/src/sample.py:64: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "WARNING:tensorflow:From /content/drive/MyDrive/gpt-2/gpt-2/src/sample.py:16: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /content/drive/MyDrive/gpt-2/gpt-2/src/sample.py:67: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.random.categorical` instead.\n",
            "WARNING:tensorflow:From src/interactive_conditional_samples.py:68: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "2022-06-25 09:55:08.662584: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 154389504 exceeds 10% of system memory.\n",
            "Model prompt >>> explain text summariation?\n",
            "======================================== SAMPLE 1 ========================================\n",
            " The answers may vary depending on which paper you are using to compile it. However, on pages where it is possible it should be a good idea to add the following to each page (or in any of the more than 100 pages you will be using):\n",
            "\n",
            "For the most part these examples will be correct and will be found as code.<|endoftext|>As of November 2018, the number of adults who were unemployed or underemployed from any time in the year was 641, which increased to a national total of 2,711, making it the highest ratio ever to those who had been unemployed out of all occupations except for civil service, according to the latest Bureau of Labor Statistics (BLS). Nearly 2 million of those jobs were filled by part time, unemployed and underemployed adults employed in the workforce from December 2005 to June 2014, with just under 1.4 million of those persons aged 16 or older who had been unemployed for more than a year. Only one hour was spent on part time, and all of it was spent by unemployed and underemployed people. The figures for youth are slightly higher, with 1,962,000 (20.3%) employed in the same job category and 1,639,000 (28.8%) in the same occupation as adults age 16 or older. Those numbers increase to nearly 1.1 million, including almost 1.7 million of those people in the youth employment category.\n",
            "\n",
            "As of April 2017, 18.3% of people aged 16 to 24 had unemployment and an average of 6.1 days unemployed\n",
            "\n",
            "The BLS numbers also provide a brief look at many other trends in the employment situation:\n",
            "\n",
            "The number of people who became non-employed at ages 16 and under for any period fell in total from a pre-recession low of 4,859,000 to a mid-recession high of 4,889,000. The number of adults aged 16 to 24 who became non-employed at any time during the year remained unchanged from the pre-recession low of 5,093,000 in late 2016 until April 2017.\n",
            "\n",
            "Over 60% of unemployed young people became non-employed at ages 15 and under. A majority were from the 16 and 26-year-olds, however, they may be expected to use an alternative employment program such as work training to supplement their full-time job.\n",
            "\n",
            "Employment levels for both genders varied substantially across the country as well. In total,\n",
            "================================================================================\n",
            "Model prompt >>> list all deep learning modules?\n",
            "======================================== SAMPLE 1 ========================================\n",
            " This can also be used to automate a lot of processing tasks, but I found this solution to be too much. Luckily this tool can be turned on by simply clicking 'Add To Workflows' of your work list.\n",
            "\n",
            "First, go to the Workflow panel, expand it to a large area, and click 'Next'. As you move on to the modules of interest click 'Add' button to add a module to your workflow, selecting it from your list of modules.\n",
            "\n",
            "To edit your workflow's modules follow the same process as a normal person, but simply double-click on the module that you want to edit and then create a new one.\n",
            "\n",
            "From here you can change the settings by clicking the button labeled 'Change Settings' in the main wizard. The process of clicking the button will return to your computer, but you won't get the list of all modules. Once all the modules are added, click 'Add to Workflows' section to edit.\n",
            "\n",
            "The first thing to do now is to open your workflow using the Import Manager. If there are problems using the new tools, just copy and paste the same message as above.\n",
            "\n",
            "We're now ready to move onto building.\n",
            "\n",
            "1) First lets take a step back to looking at the workflow process in terms of working with modules, and how it has been used. To see how this can be accomplished right click on our project, and navigate to 'Designs' (or in many cases, right click on 'Workflow')\n",
            "\n",
            "'Designs' is a module based workflow tool that comes with one main focus. It is useful when working with different aspects of the workflow, and not only when working in a collaborative format. We'll look at a few examples below to give you a solid understanding of how it works and where it comes from.\n",
            "\n",
            "Here's a screenshot using the previous image and how this process works. You can also see it with a nice zoomed-out image showing your new look and activity:\n",
            "\n",
            "\n",
            "If we'd had the same setup in our earlier project, we would have seen a much clearer visual of how to use the workflow. It would have been quite obvious which section was 'building', and with it the tool would have been able to do the work. Now we're looking at a couple of common approaches that can be used in this way.\n",
            "\n",
            "1) Importing and manipulating images\n",
            "\n",
            "Importing a collection has multiple aspects – it can be used for image editing, importing a\n",
            "================================================================================\n",
            "Model prompt >>> "
          ]
        }
      ]
    }
  ]
}